# Defending-Digital-Discourse-Developing-a-Toxic-Classifier-for-Fostering-Healthy-Online-Communities
Defending Digital Discourse Developing a Toxic Comment Classifier for Fostering Healthy Online Communities


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Code Summaries</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
        }
        h2 {
            color: #333;
        }
        code {
            background-color: #f4f4f4;
            padding: 5px 10px;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <h2>Project 1: Toxic Comment Classification</h2>

    <h3>Code Snippet 1:</h3>
    <p>This code snippet performs data visualization and preprocessing for toxic comment classification. It includes visualizing the distribution of toxic labels and cleaning the text data.</p>

    <h3>Code Snippet 2:</h3>
    <p>It trains logistic regression models for each toxic label using TF-IDF vectorization. The models are evaluated using ROC AUC score, and misclassified examples are analyzed.</p>

    <h3>Code Snippet 3:</h3>
    <p>The code trains a Multinomial Naive Bayes classifier and performs feature analysis to understand the importance of words in predicting toxic comments.</p>

    <h3>Code Snippet 4:</h3>
    <p>This snippet makes predictions using the trained logistic regression models and provides the probability of comments being toxic for each label.</p>

    <!-- Repeat the above structure for the other projects and code snippets -->

</body>
</html>
